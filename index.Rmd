---
title       : FFTrees
subtitle    : An R package to create, visualize, and implement fast and frugal decision trees
author      : Nathaniel Phillips, Economic Psychology, University of Basel
job         : BaselR Meeting, March 2017
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : tomorrow      # 
widgets     : []            # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
knit        : slidify::knit2slides
logo : FFTrees_Logo.jpg
biglogo : FFTrees_Logo.jpg
---


```{r echo = FALSE, message = FALSE, results = "hide"}
load("../data/BaselR_FFTrees.RData")
load("../data/forensictrees.RData")
library(FFTrees)
```


## A growing problem at the Cook County Hospital in 1996

```{r cookmap, fig.margin = TRUE, echo = FALSE, eval = TRUE, out.width = "70%", fig.align='center'}
knitr::include_graphics(c("images/cookmap.png"))
```


--- .class #id 

## Patient overload

```{r, fig.margin = TRUE, echo = FALSE, eval = TRUE, out.width = "70%", fig.align='center'}
knitr::include_graphics(c("images/crowdedemergency.jpg"))
```




--- &twocol

*** =left

## Diagnosing heart attacks

<!-- A significant number of those people filing into the ED—on average, about thirty a day—were worried that they were having a heart attack.  Chest-pain patients were resource-intensive. The treatment protocol was long and elaborate and—worst of all—maddeningly inconclusive. -->

- 30 people a day worried about a heart attack. 
- Coronary care bed costs $2,000 a night and requires a 3 day stay.
- Send true heart attacks to the coronary care bed, and true healthy patients to a normal bed.

### Multiple, uncertain measures

- Electrocardiogram (ECG), Blood pressure, Stethescope, How long? How much? During exercise? History? Cholesterol? Drugs? etc.


*** =right

```{r , fig.margin = TRUE, echo = FALSE, out.width = "100%", fig.align='center'}
knitr::include_graphics(c("images/chestpain.jpg"))
```

--- .class #id 

## How good were doctor's intuitive decisions?

- Task: Estimate from 0 to 100 the probability of a heart attack of 20 separate patients.

```{r, fig.margin = TRUE, echo = FALSE, eval = TRUE, out.width = "30%", fig.align='center'}
knitr::include_graphics(c("images/medicalhistory.jpg"))
```

--- .class #id 

## Answer: Not consistent

### "In each case the answers we got pretty much ranged from 0 to 100. It was extraordinary" (Brenden Reilly, Department of Medicine chairman)

```{r, fig.margin = TRUE, echo = FALSE, eval = TRUE, out.width = "70%", fig.align='center'}
knitr::include_graphics(c("images/arguingdoctors.jpg"))
```


--- .class #id 

## Solution

- A fast and frugal decision tree (FFT) developed by a cardiologist named Lee Goldman.


```{r , fig.margin = TRUE, echo = FALSE, out.width = "20%", fig.align='center'}
knitr::include_graphics(c("images/cooktree.png"))
```


### Why use a decision tree?

> - Speed, Consistency, Easy to understand and use 'in the head'


--- .class #id 


```{r , fig.margin = TRUE, echo = FALSE, out.width = "40%", fig.align='center'}
knitr::include_graphics(c("images/cooktree.png"))
```


---  &twocol

*** =left

## The Cook hospital decision tree

- Over two years, the performance of the tree was compared to the physician's intuitive judgments.

### Results

> - Doctor's accuracy: 75-90%
> - Decision tree accuracy: 95%
> - Tree had far fewer false-positives and huge cost savings
> - To this day, the tree is still used at the hospital.

*** =right

```{r , fig.margin = TRUE, echo = FALSE, out.width = "80%", fig.align='center'}
knitr::include_graphics(c("images/cooktree.png"))
```




---  &twocol

*** =left
## Standard decision tree

> - Standard decision trees created by unrestricted algorithms can become very complex

> - Complexity -> High costs, Difficult to understand, prone to overfitting. 

```{r , fig.margin = TRUE, echo = FALSE, out.width = "100%", fig.align='center', message = FALSE, echo = FALSE}
knitr::include_graphics(c("images/complextree.png"))
```

*** =right

## Fast and Frugal tree

> - A fast and frugal decision tree (FFT) is a very simple, highly restricted decision tree where each node has exactly two branches, where at least one branch is an exit branch (Martignon et al., 2008).

> - FFTs -> Cheap, easy to understand, and rarely overfit.


```{r , fig.margin = TRUE, echo = FALSE, out.width = "60%", fig.align='center', message = FALSE, echo = FALSE}
knitr::include_graphics(c("images/traintreestats.png"))
```

<!-- --- .class #id  -->

<!-- ## Depression Tree -->

<!-- - Jenny et al. (2013): Simple rules for detecting depression -->

<!-- ```{r , fig.margin = TRUE, echo = FALSE, out.width = "40%", fig.align='center'} -->
<!-- knitr::include_graphics(c("images/depressiontree.png")) -->
<!-- ``` -->

<!-- --- .class #id  -->

<!-- ## Bank failure -->

<!-- - Neth et al. (2013): Homo heuristics in the financial world: From risk management to managing uncertainty -->

<!-- ```{r , fig.margin = TRUE, echo = FALSE, out.width = "40%", fig.align='center'} -->
<!-- knitr::include_graphics(c("images/nethtree.png")) -->
<!-- ``` -->

<!-- --- &twocol -->

<!-- ## Patient success -->

<!-- *** =left -->



<!-- ### FFT -->
<!-- ```{r echo = FALSE} -->
<!-- library(FFTrees) -->
<!-- plot(tree.63.m, stats = FALSE, tree = 5) -->
<!-- ``` -->



<!-- *** =right -->


<!-- ### rpart tree -->
<!-- ```{r echo = FALSE} -->
<!-- plot(rpart.63) -->
<!-- text(rpart.63) -->
<!-- ``` -->

--- .class #id 
## Problem

- There is no off-the-shelf method to construct FFTs.
  - Previous researchers have individually constructed their FFTs.

### Task
- Create an easy-to-use R package that constructs, visualizes, and implements FFTs.

```{r , fig.margin = TRUE, echo = FALSE, out.width = "30%", fig.align='center', message = FALSE, echo = FALSE}
knitr::include_graphics(c("images/FFTrees_Logo.jpg"))
```


--- .class #id 
## FFTrees

```{r, eval = FALSE}
# v1.1.8 available on CRAN
install.packages("FFTrees")

# v1.2.0 on github
devtools::github("ndphillips/FFTrees", include_vignette = TRUE)
```


--- .class #id 
## Heart disease datatset

```{r, message = FALSE}
library(FFTrees)

head(heartdisease)
```

--- .class #id 
## Creating a Heart Disease FFT

```{r, message = FALSE}
# Step 1: Create training and test data
set.seed(100)

heartdisease <- heartdisease[sample(nrow(heartdisease)),]
heart.train <- heartdisease[1:150,]
heart.test <- heartdisease[151:303,]

# Step 2: Create heart.fft
heart.fft <- FFTrees(formula = diagnosis ~.,
                     data = heart.train,
                     data.test = heart.test)
```

<!-- --- .class #id  -->
<!-- ## Evaluating a decision algorithm -->


<!-- ```{r , fig.margin = TRUE, echo = FALSE, out.width = "60%", fig.align='center'} -->
<!-- knitr::include_graphics(c("images/confusiontable.png")) -->
<!-- ``` -->




--- .class #id 
## FFT summary statistics

```{r, message = FALSE, echo = TRUE}
# Step 3: Summary statistics
heart.fft
```

--- &twocol

*** =left

## Heart Disease FFT
```{r, eval = TRUE, fig.align = 'center', echo = FALSE}
plot(heart.fft, main = "Heart Disease", 
     decision.names = c("Healthy", "Diseased"), stats = FALSE)
```



*** =right

### 3 cues


| cue| description|values |
|:------|:----|:-----|
|     `thal`|    thallium scintigraphy, a nuclear imaging test that shows how well blood flows into the heart.|normal (n), indicate a fixed defect (fd), or a reversible defect (rd)     |
|     `cp`|    Chest pain type| Typical angina (ta), atypical angina (aa), non-anginal pain (np), or asymptomatic (a)     |
|     `ca`| Number of major vessels colored by flourosopy, a continuous x-ray imaging tool|0, 1, 2 or 3 |


--- .class #id 
## Heart Disease FFT | Training
```{r, eval = TRUE, echo = FALSE, fig.align = "center", fig.width = 8, fig.height = 7}
plot(heart.fft, main = "Heart Disease", decision.names = c("healthy", "sick"))
```



--- .class #id 
## Heart Disease FFT | Prediction

```{r, eval = TRUE, echo = FALSE, fig.align = "center", fig.width = 8, fig.height = 7}
plot(heart.fft, main = "Heart Disease", decision.names = c("healthy", "sick"), data = "test")
```


--- .class #id 
## Heart Disease FFT | ROC

```{r , fig.margin = TRUE, echo = FALSE, out.width = "80%", fig.align='center'}
knitr::include_graphics(c("images/roc.png"))
```


--- .class #id 
## Heart Disease FFT | Tree 4

```{r, eval = TRUE, echo = FALSE, fig.align = "center", fig.width = 8, fig.height = 7}
plot(heart.fft, 
     main = "Heart Disease", 
     decision.names = c("healthy", "sick"), 
     data = "test")
```



--- .class #id 
## Heart Disease FFT | Tree 3

```{r, message = FALSE, fig.align = 'center', echo = FALSE, message = FALSE, results = "hide", fig.width = 8, fig.height = 7}

plot(heart.fft, main = "Heart Disease", 
     decision.names = c("healthy", "sick"), data = "test", tree = 3)
```

--- .class #id
## Heart Disease FFT | Tree 6

```{r, message = FALSE, fig.align = 'center', echo = FALSE, message = FALSE, results = "hide", fig.width = 8, fig.height = 7}

plot(heart.fft, main = "Heart Disease", 
     decision.names = c("healthy", "sick"), data = "test", tree = 6)
```

<!-- --- .class #id  -->
<!-- ## How do FFTs compare to regression and CART? -->

<!-- - Simplicity: *How much information is used and how is it combined?* -->
<!-- - Accuracy: *How well can the algorithm predict new data?* -->

<!-- --- .class #id  -->
<!-- ## Heart disease: regression -->
<!-- - 4 significant cues: (sex, cp, trestbps, ca) -->

<!-- ```{r echo = FALSE, fig.width = 10, fig.height = 6, fig.align = 'center'} -->
<!-- heart.lm <- glm(diagnosis ~., data = heartdisease, family = "binomial") -->
<!-- #heart.lm$coefficients -->
<!-- #summary(heart.lm)$coefficients -->

<!-- bar.cols <- rep("white", nrow(summary(heart.lm)$coefficients)) -->
<!-- bar.cols[summary(heart.lm)$coefficients[,4] < .05] <- yarrr::piratepal("basel", trans = .6, length.out = sum(summary(heart.lm)$coefficients[,4] < .05)) -->

<!-- barplot(height = abs(summary(heart.lm)$coefficients[,3]),  -->
<!--         names.arg = rownames(summary(heart.lm)$coefficients), -->
<!--         col = bar.cols, ylab = "Coefficient z-scores", main = "Heart Disease logistic regression") -->

<!-- abline(h = 1.96) -->

<!-- ``` -->



--- .class #id 
## Heart disease cue accuracies

```{r eval = TRUE, fig.align = 'center'}
plot(heart.fft, what = "cues", main = "Heart Disease")
```



--- .class #id 
## FFForest()

### Visualise cue importance and co-occurence

```{r, fig.width = 12, fig.height = 7, fig.align = 'center', echo = FALSE}
plot(heart.fff)
```


--- .class #id 
## Comparing FFTs to standard trees


### How does the FFT created by FFTrees compare to a 'standard' decision tree created by rpart?


--- &twocol

*** =left
## Heart disease: rpart

- 8 cues (thal, cp, oldpeak, ca, age, exang, thalach, chol)

```{r, out.width = "80%", echo = FALSE, fig.align = 'center'}
heart.rpart <- rpart::rpart(diagnosis ~., data = heartdisease)
plot(heart.rpart)
text(heart.rpart)
```


**** =right
## Heart disease: FFT

> - 3 cues (thal, cp, ca)


<!-- |     |  train|   test| -->
<!-- |:----|------:|------:| -->
<!-- |n    | 150.00| 153.00| -->
<!-- |pci  |   0.87|   0.88| -->
<!-- |mcu  |   1.87|   1.62| -->
<!-- |acc  |   0.81|   0.80| -->
<!-- |bacc |   0.79|   0.79| -->
<!-- |sens |   0.63|   0.63| -->
<!-- |spec |   0.95|   0.94| -->

> - The FFT is very cheap to implement
>    - Heart disease FFT: $75.91
>    - Regression: $300 


```{r , fig.margin = TRUE, echo = FALSE, out.width = "70%", fig.align='center', message = FALSE, echo = FALSE}
knitr::include_graphics(c("images/traintreestats.png"))
```

<!-- ```{r, eval = TRUE, fig.align = 'center', echo = FALSE} -->
<!-- plot(heart.fft,  -->
<!--      main = "Heart Disease",  -->
<!--      decision.names = c("healthy", "sick"), -->
<!--      stats = FALSE) -->
<!-- ``` -->


--- .class #id
## Heart disease classification accuracy

```{r, echo = FALSE,  fig.align = 'center', out.width = "80%", message = FALSE, results = "hide"}
heart.sim <- data.frame(model = c(rep("FFT", 100),
                                  rep("LR", 100),
                                  rep("CART", 100)),
                        data = c(rep("train", 300), rep("test", 300)),
                        bacc = c(heart.fff$tree.sim$bacc.train,
                                          heart.fff$lr.sim$bacc.train,
                                          heart.fff$cart.sim$bacc.train,
                                 heart.fff$tree.sim$bacc.test,
                                          heart.fff$lr.sim$bacc.test,
                                          heart.fff$cart.sim$bacc.test))
```


```{r, echo = FALSE,  fig.align = 'center', fig.width = 10, fig.height = 7, message = FALSE, results = "hide"}
yarrr::pirateplot(bacc ~ model + data, data = heart.sim, ylim = c(.6, 1), sortx = "s", main = "Simulation performance in Heart disease", ylab = "Balanced Accuracy (bacc)", yaxt = "n", gl.col = "white")
axis(side = 2, at = seq(.6, 1, .1), las = 1)
rect(-1000, -1000, 10000, 1000, col = "white", border = NA)
grid()
```



--- .class #id
## Heart disease classification accuracy

```{r, echo = FALSE,  fig.align = 'center', fig.width = 10, fig.height = 7, message = FALSE, results = "hide"}
yarrr::pirateplot(bacc ~ model + data, data = heart.sim, ylim = c(.6, 1), sortx = "s", main = "Simulation performance in Heart disease", ylab = "Balanced Accuracy (bacc)", yaxt = "n", gl.col = "white")
axis(side = 2, at = seq(.6, 1, .1), las = 1)
rect(4, -1000, 10000, 1000, col = "white", border = NA)
grid()
```

--- .class #id
## Heart disease classification accuracy


```{r, echo = FALSE,  fig.align = 'center', fig.width = 10, fig.height = 7, message = FALSE, results = "hide"}
yarrr::pirateplot(bacc ~ model + data, data = heart.sim, ylim = c(.6, 1), sortx = "s", main = "Simulation performance in Heart disease", ylab = "Balanced Accuracy (bacc)", yaxt = "n", gl.col = "white")
axis(side = 2, at = seq(.6, 1, .1), las = 1)
grid()
```


--- .class #id 
## How accurate are FFTs built by FFTrees?

- Prediction competition
    - 10 datasets taken from the UCI machine learning database
    - 50% Fitting / 50% Prediction subsample splitting, DV: balanced accuracy = (sensitivity + specificity) / 2

|dataset     | cases| cues| base.rate|
|:-----------|-----:|----:|---------:|
|arrhythmia  |    68|  280|      0.29|
|audiology   |   226|   70|      0.10|
|breast      |   683|   10|      0.35|
|bridges     |    92|   10|      0.39|
|cmc         |  1473|   10|      0.35|

Table: 5 of the 10 prediction datasets

--- .class #id 
## Aggregate simulation prediction results

```{r , fig.margin = TRUE, echo = FALSE, out.width = "90%", fig.align='center'}
knitr::include_graphics(c("images/simulationagg_a.png"))
```


--- .class #id 
## Aggregate simulation prediction results

```{r , fig.margin = TRUE, echo = FALSE, out.width = "90%", fig.align='center'}
knitr::include_graphics(c("images/simulationagg_b.png"))
```

--- .class #id 
## Aggregate simulation prediction results

```{r , fig.margin = TRUE, echo = FALSE, out.width = "90%", fig.align='center'}
knitr::include_graphics(c("images/simulationagg_c.png"))
```


--- .class #id 
## Simulation prediction results by dataset

```{r , fig.margin = TRUE, echo = FALSE, out.width = "90%", fig.align='center'}
knitr::include_graphics(c("images/simulation.png"))
```

--- &twocol

*** =left

## Conclusions

> - FFTrees makes it easy to develop simple, effective, transparent decision trees.
> - FFTrees can compete with complex decision algorithms, even Random Forests and Support Vector machines, in pure prediction.


## Next steps


> - Speed up code with c++ or Julia.
> - Include *cue costs* into algorithm.
> - Quantify when and how a tree **fails** when it is applied to data over time.

*** =right

```{r , fig.margin = TRUE, echo = FALSE, out.width = "100%", fig.align='center', message = FALSE, echo = FALSE}
knitr::include_graphics(c("images/traintreestats.png"))
```


--- &twocol

*** =left

## Please help and contribute!

- I want more real-world tests of `FFTrees`! If you have data you want to try `FFTrees` on, or can think of new features, please let me know and I would be happy to collaborate.

- I am very happy for contributions and bug reports at `github.com/ndphillips/FFTrees`, 

*** =right

[](https://www.revive-adserver.com/media/GitHub.jpg)

```{r , fig.margin = TRUE, echo = FALSE, out.width = "100%", fig.align='center', message = FALSE, echo = FALSE}
knitr::include_graphics("https://www.revive-adserver.com/media/GitHub.jpg")
```


--- .class #id 
## Questions?

```{r, eval = TRUE, fig.width = 8, fig.height = 7, fig.align='center', echo = FALSE}
plot(heart.fft, 
     main = "Heart Disease", 
     decision.names = c("healthy", "sick"))
```

--- &twocol

*** =left
## FFTrees algorithm

1. Calculate a decision threshold `t` for each cue that maximizes the cue’s balanced accuracy `bacc` in training.

2. Rank cues in order of their maximum balanced accuracy -- select the top N cues. 

3. Creates all possible `2^{N−1}` trees with these cues, using all exit structures.

*** =right

```{r echo = FALSE, fig.align = 'center'}
heartdisease$chol.cut <- cut(heartdisease$chol, breaks = 10)

cutoffs <- seq(min(heartdisease$chol), max(heartdisease$chol), length.out = 10)

vals <- sapply(cutoffs, FUN = function(x) {
  
  acc <- mean(heartdisease$diagnosis[heartdisease$chol >= x]) * .5 +
         mean(heartdisease$diagnosis[heartdisease$chol < x] == FALSE) * .5
  
})


plot(cutoffs, vals, ylab = "bacc", xlab = "Decision Threshold", main = "Cholestorol", type = "b", ylim = c(0, 1))

text(cutoffs, vals, paste(">", round(cutoffs, 0)), pos = 3)

with(subset(heartdisease, diagnosis == 1), 
     points(chol, rep(.9, length(chol)) + rnorm(length(chol), mean = 0, sd = .02), pch = 21, bg = yarrr::transparent("red", .6), col = "white"))

with(subset(heartdisease, diagnosis == 0), 
     points(chol, rep(.8, length(chol)) + rnorm(length(chol), mean = 0, sd = .02), pch = 21, bg = yarrr::transparent("blue", .6), col = "white"))

```



